# Baseline 50 44
python train_mlp_tf.py --name mlp_adam

# Fancy optimizer 57 51.4
python train_mlp_tf.py --name mlp_adam --optimizer rmsprop --learning_rate 0.00007 --max_steps 2000

# More neurons 62 52.9 (seems like we should regularize)
python train_mlp_tf.py --name mlp_adam --dnn_hidden_units 200,200 --optimizer rmsprop --learning_rate 0.0003 --max_steps 2000

# Best 60 53
python train_mlp_tf.py --name mlp_adam --dnn_hidden_units 200,200 --optimizer adam --learning_rate 3e-4 --max_steps 2000 --weight_reg_strength 0.0001

# 57 53.9
python train_mlp_tf.py --name mlp_adam --dnn_hidden_units 250,250 --optimizer adam --learning_rate 0.0001 --max_steps 2000 --dropout_rate 0.1

# 50 54
python train_mlp_tf.py --name mlp_adam --dnn_hidden_units 500,500 --optimizer adam --learning_rate 0.0002 --max_steps 2000 --dropout_rate 0.2

# 59 54.4
python train_mlp_tf.py --name mlp_adam --dnn_hidden_units 250,250 --optimizer adam --learning_rate 0.0002 --max_steps 2000 --dropout_rate 0.1
